{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merge.preprocessing.tokenizer import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.create(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.create(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"Hello, my dog is cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = load_dataset(\"roneneldan/TinyStories\", split=\"train\", cache_dir=\"./hf_cache\", num_proc=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/git/leon/merge/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from merge.preprocessing.tokenizer import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.create(\"EleutherAI/gpt-neo-125m\")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonericsson/projects/github/merge/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from merge.preprocessing.tokenizer import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.create(\"microsoft/phi-2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "\n",
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merge.modules.attention import causal_attention_mask\n",
    "\n",
    "mask = causal_attention_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "attention_mask = torch.tensor([1, 1, 1, 0, 0]).repeat(5, 1)\n",
    "\n",
    "attention_mask = attention_mask.repeat(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonericsson/projects/github/merge/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from merge.preprocessing.tokenizer import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.create(\"EleutherAI/gpt-neo-125m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": \"<|pad|>\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Let's simulate a vocabulary where:\n",
    "# pad_token_id = 0\n",
    "# a_token_id = 1\n",
    "# b_token_id = 2\n",
    "# vocab_size = 3\n",
    "\n",
    "# Original sequence: \"aab\" padded to length 5\n",
    "original = torch.tensor([[1, 1, 2, 0, 0, 0]])  # [a, a, b, pad, pad]\n",
    "input_ids = original[:, :-1]  # [a, a, b, pad, pad]\n",
    "target_ids = original[:, 1:] # [a, b, pad, pad, pad]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 2, 0, 0]]), tensor([[1, 2, 0, 0, 0]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake logits - we'll make them \"perfect\" predictions\n",
    "# Shape: (batch=1, seq=5, vocab=3)\n",
    "logits = torch.zeros(1, 5, 3)\n",
    "# For each position, make the correct prediction have highest probability\n",
    "logits[0, 0, 1] = 10.0  # predict 'a' at position 0\n",
    "logits[0, 1, 2] = 10.0  # predict 'b' at position 1\n",
    "# We don't care about the predictions for padded positions\n",
    "\n",
    "# Test both with and without ignore_index\n",
    "criterion_with_ignore = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "criterion_without_ignore = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with ignore_index=0: 9.083335316972807e-05\n",
      "Loss without ignore_index: 0.6592037081718445\n"
     ]
    }
   ],
   "source": [
    "# Reshape for loss calculation\n",
    "batch, seq, vocab = logits.shape\n",
    "logits_reshaped = logits.reshape(batch * seq, vocab)\n",
    "target_ids_reshaped = target_ids.reshape(batch * seq)\n",
    "\n",
    "loss_with_ignore = criterion_with_ignore(logits_reshaped, target_ids_reshaped)\n",
    "loss_without_ignore = criterion_without_ignore(logits_reshaped, target_ids_reshaped)\n",
    "\n",
    "print(f\"Loss with ignore_index=0: {loss_with_ignore.item()}\")\n",
    "print(f\"Loss without ignore_index: {loss_without_ignore.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
